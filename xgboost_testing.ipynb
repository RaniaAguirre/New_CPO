{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47d29b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adrianlopez/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/Users/adrianlopez/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.4' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'BasePortfolioModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mxgb\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cross_val_score\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mXGBoostModel\u001b[39;00m(\u001b[43mBasePortfolioModel\u001b[49m):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, optimize_hyperparams\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimize_hyperparams \u001b[38;5;241m=\u001b[39m optimize_hyperparams\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BasePortfolioModel' is not defined"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "class XGBoostModel(BasePortfolioModel):\n",
    "    def __init__(self, n_estimators=100, max_depth=3, learning_rate=0.1, optimize_hyperparams=False):\n",
    "        self.optimize_hyperparams = optimize_hyperparams\n",
    "        self.model = xgb.XGBRegressor(n_estimators=n_estimators, max_depth=max_depth,\n",
    "                                      learning_rate=learning_rate, objective='reg:squarederror')\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"Entrena el modelo y realiza tuning si está activado\"\"\"\n",
    "        if self.optimize_hyperparams:\n",
    "            def objective(trial):\n",
    "                \"\"\"Función objetivo para optimización de hiperparámetros\"\"\"\n",
    "                params = {\n",
    "                    'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "                    'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "                    'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "                    'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "                    'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "                    'gamma': trial.suggest_float('gamma', 0, 0.5),\n",
    "                    'reg_alpha': trial.suggest_float('reg_alpha', 0, 1.0),\n",
    "                    'reg_lambda': trial.suggest_float('reg_lambda', 0.1, 2.0)\n",
    "                }\n",
    "\n",
    "                model = xgb.XGBRegressor(**params, objective='reg:squarederror')\n",
    "                scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')\n",
    "                return scores.mean()\n",
    "\n",
    "            study = optuna.create_study(direction='maximize')\n",
    "            study.optimize(objective, n_trials=30)\n",
    "\n",
    "            best_params = study.best_params\n",
    "            print(\"Mejores hiperparámetros encontrados:\", best_params)\n",
    "\n",
    "            # Crear modelo con los mejores hiperparámetros\n",
    "            self.model = xgb.XGBRegressor(**best_params, objective='reg:squarederror')\n",
    "\n",
    "        # Entrenar el modelo final\n",
    "        self.model.fit(X_train, y_train)\n",
    "        print(\"XGBoost model fitted.\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "189c84a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Cargar los datos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msampled_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Dividir entre X e y\u001b[39;00m\n\u001b[1;32m      5\u001b[0m X \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Cargar los datos\n",
    "df = pd.read_csv('sampled_data.csv')\n",
    "\n",
    "# Dividir entre X e y\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Separar en Train y Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar modelo con tuning activado\n",
    "xgb_model = XGBoostModel(optimize_hyperparams=True)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el modelo\n",
    "xgb_model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69771565",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
